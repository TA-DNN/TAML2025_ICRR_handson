{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Hands-On 2: Neural networks for regression - simple energy reconstruction with TA\n",
    "\n",
    "We trained a simple model yesterday for the energy reconstruction from TA SD simulation. Today we will revise this task and train one of the proposed architectures we saw today to estimate the energy. No need for visualizing the data today.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data from ascii file \n",
    "\n",
    "We load the data as we did before and normalize the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "# Set device (GPU if available, mps on Mac, else CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosmicRayDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        # Store the input features (X_data) and target values (y_data)\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve a single sample at the given index\n",
    "        X_sample = self.X_data[index]\n",
    "        y_sample = self.y_data[index]\n",
    "        # return torch.tensor(X_sample, dtype=torch.float32), torch.tensor(y_sample, dtype=torch.float32)\n",
    "        return X_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data again in case some variables have been overwritten\n",
    "data_total_signal = np.loadtxt(\"../day1/total_signal_prot.txt\", comments=\"#\", dtype=np.float32)\n",
    "data_arrival_times = np.loadtxt(\"../day1/arrival_times_prot.txt\", comments=\"#\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in a dictionary\n",
    "data = dict()\n",
    "data[\"energy\"] = data_total_signal[:, 1]\n",
    "data[\"shower_axis\"] = data_total_signal[:, 2:5]\n",
    "data[\"total_signal\"] = data_total_signal[:, 5:].reshape(-1, 7, 7)\n",
    "data[\"arrival_times\"] = data_arrival_times[:, 5:].reshape(-1, 7, 7)\n",
    "\n",
    "data[\"total_signal\"] = (data[\"total_signal\"] - data[\"total_signal\"].min()) / (data[\"total_signal\"].max() - data[\"total_signal\"].min())\n",
    "data[\"arrival_times\"] = (data[\"arrival_times\"] - data[\"arrival_times\"].min()) / (data[\"arrival_times\"].max() - data[\"arrival_times\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51653, 7, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"total_signal\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape total_signal and arrival_time into 2D grids\n",
    "total_signal = torch.tensor(data[\"total_signal\"], dtype=torch.float32).to(device)  # [batch, 7, 7]\n",
    "arrival_time = torch.tensor(data[\"arrival_times\"], dtype=torch.float32).to(device)  # [batch, 7, 7]\n",
    "energy = torch.tensor(data[\"energy\"], dtype=torch.float32).to(device)\n",
    "\n",
    "# Combine them into a 2-channel tensor\n",
    "combined_features = torch.stack((total_signal, arrival_time), dim=1)  # Shape: [batch, 2, 7, 7]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, energy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data from (batch_size, 98) -> (batch_size, 2, 7, 7)\n",
    "X_train_cnn = X_train.view(-1, 2, 7, 7)\n",
    "X_test_cnn = X_test.view(-1, 2, 7, 7)\n",
    "\n",
    "# Update DataLoader with new shapes\n",
    "train_dataset = CosmicRayDataset(X_train_cnn, y_train)\n",
    "test_dataset = CosmicRayDataset(X_test_cnn, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Train and evalulate the model\n",
    "\n",
    "We are familiar with this step from the previous exercise and will simply take the same model for regression. We use the function from utils and modify it for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_monitor(\n",
    "    device,\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    num_epochs,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    plot_interval=1,\n",
    "):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Set up a single plot for loss\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "    pbar = tqdm(total=num_epochs, leave=True)\n",
    "\n",
    "    hdisplay_img = display(display_id=True)\n",
    "    hdisplay_pbar = display(display_id=True)\n",
    "    title = f\"|{'Epoch':^20}|{'Train loss':^20}|{'Validation loss':^20}|\"\n",
    "    print(title)\n",
    "    print(\"_\" * len(title))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Step 3: Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Step 4: Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(testloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # tqdm progress bar\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        pbar.update()\n",
    "\n",
    "        # Plotting updates every `plot_interval` epochs\n",
    "        if (epoch + 1) % plot_interval == 0:\n",
    "            # Clear the previous plot\n",
    "            ax1.clear()\n",
    "\n",
    "            # Plot training and validation loss\n",
    "            ax1.plot(range(1, epoch + 2), train_losses, \"b-\", label=\"Train Loss\")\n",
    "            ax1.plot(range(1, epoch + 2), val_losses, \"r-\", label=\"Val Loss\")\n",
    "            ax1.set_xlabel(\"Epoch\")\n",
    "            ax1.set_ylabel(\"Loss\")\n",
    "            ax1.set_title(\"Loss\")\n",
    "            ax1.legend()\n",
    "            ax1.grid(linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "            # Update the plot in the notebook\n",
    "            hdisplay_img.update(fig)\n",
    "\n",
    "        # Print losses at each epoch\n",
    "        print(f\"|{epoch+1:^20}|{train_loss:^20.4f}|{avg_val_loss:^20.4f}|\")\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_cosmic_ray_model(model, X_test, y_test, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        outputs = model(X_test)\n",
    "        loss = criterion(outputs, y_test)\n",
    "    print(f'Test Loss: {loss.item():.4f}')\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "\n",
    "Take one of the presented architectures and train a model for regression. Evaluate its performance with the training monitor function above and plot predicted energies vs. true energy. Discuss the performance and which steps to take for potential improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tadnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
